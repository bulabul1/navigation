"""
å…¨é¢åˆ†ææœ€è¿‘ä¸€æ¬¡è®­ç»ƒçš„è¡¨ç°
"""

import json
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

# è¯»å–è®­ç»ƒå†å²
log_dir = Path("logs/resume_training_optimized_20251006_184735")
with open(log_dir / "training_history.json", 'r') as f:
    history = json.load(f)

episode_returns = np.array(history['episode_returns'])
episode_lengths = np.array(history['episode_lengths'])

print("=" * 80)
print("è®­ç»ƒæ€»ç»“æŠ¥å‘Š".center(80))
print("=" * 80)

# åŸºæœ¬ç»Ÿè®¡
total_episodes = len(episode_returns)
print(f"\nğŸ“Š **è®­ç»ƒåŸºæœ¬ä¿¡æ¯**")
print(f"  æ€»Episodeæ•°: {total_episodes}")
print(f"  Episode Return èŒƒå›´: [{episode_returns.min():.2f}, {episode_returns.max():.2f}]")
print(f"  Episode Length èŒƒå›´: [{episode_lengths.min():.0f}, {episode_lengths.max():.0f}]")

# æŒ‰é˜¶æ®µåˆ†æ (æ¯100 episodes)
print(f"\nğŸ“ˆ **åˆ†é˜¶æ®µè¡¨ç°** (æ¯100é›†ç»Ÿè®¡)")
print(f"{'é˜¶æ®µ':<15} {'å¹³å‡Return':<15} {'å¹³å‡Length':<15} {'æˆåŠŸç‡':<15}")
print("-" * 60)

for i in range(0, total_episodes, 100):
    end_idx = min(i + 100, total_episodes)
    stage_returns = episode_returns[i:end_idx]
    stage_lengths = episode_lengths[i:end_idx]
    
    # æˆåŠŸç‡ï¼šReturn > 0
    success_rate = (stage_returns > 0).sum() / len(stage_returns)
    
    print(f"Ep {i:3d}-{end_idx:3d}    "
          f"{stage_returns.mean():>10.2f}     "
          f"{stage_lengths.mean():>10.1f}     "
          f"{success_rate:>10.1%}")

# æœ€å50é›†è¯¦ç»†åˆ†æ
print(f"\nğŸ¯ **æœ€å50é›†è¯¦ç»†åˆ†æ**")
last_50_returns = episode_returns[-50:]
last_50_lengths = episode_lengths[-50:]

success_count = (last_50_returns > 0).sum()
collision_count = (last_50_returns < -50).sum()  # å‡è®¾ç¢°æ’å¯¼è‡´å¤§è´Ÿå¥–åŠ±
timeout_count = 50 - success_count - collision_count

print(f"  å¹³å‡Return: {last_50_returns.mean():.2f} (Â±{last_50_returns.std():.2f})")
print(f"  å¹³å‡Length: {last_50_lengths.mean():.1f} (Â±{last_50_lengths.std():.1f})")
print(f"  æˆåŠŸåˆ°è¾¾: {success_count}/50 ({success_count/50:.1%})")
print(f"  ç¢°æ’ç»ˆæ­¢: {collision_count}/50 ({collision_count/50:.1%})")
print(f"  è¶…æ—¶ç»ˆæ­¢: {timeout_count}/50 ({timeout_count/50:.1%})")

# æœ€ä½³/æœ€å·®è¡¨ç°
print(f"\nğŸ† **æå€¼åˆ†æ**")
best_idx = episode_returns.argmax()
worst_idx = episode_returns.argmin()

print(f"  æœ€ä½³Episode: Ep {best_idx} (Return={episode_returns[best_idx]:.2f}, Length={episode_lengths[best_idx]:.0f})")
print(f"  æœ€å·®Episode: Ep {worst_idx} (Return={episode_returns[worst_idx]:.2f}, Length={episode_lengths[worst_idx]:.0f})")

# Episode Lengthåˆ†å¸ƒåˆ†æ
print(f"\nâ±ï¸  **Episode Lengthåˆ†å¸ƒ**")
very_short = (episode_lengths <= 10).sum()
short = ((episode_lengths > 10) & (episode_lengths <= 30)).sum()
medium = ((episode_lengths > 30) & (episode_lengths <= 100)).sum()
long = (episode_lengths > 100).sum()

print(f"  æçŸ­ (â‰¤10æ­¥): {very_short}/{total_episodes} ({very_short/total_episodes:.1%})")
print(f"  çŸ­ (11-30æ­¥): {short}/{total_episodes} ({short/total_episodes:.1%})")
print(f"  ä¸­ (31-100æ­¥): {medium}/{total_episodes} ({medium/total_episodes:.1%})")
print(f"  é•¿ (>100æ­¥): {long}/{total_episodes} ({long/total_episodes:.1%})")

# è¶‹åŠ¿åˆ†æï¼ˆä½¿ç”¨ç§»åŠ¨å¹³å‡ï¼‰
window = 50
if len(episode_returns) >= window:
    moving_avg = np.convolve(episode_returns, np.ones(window)/window, mode='valid')
    
    print(f"\nğŸ“‰ **å­¦ä¹ è¶‹åŠ¿** (50-episodeç§»åŠ¨å¹³å‡)")
    first_avg = moving_avg[:50].mean()
    last_avg = moving_avg[-50:].mean()
    improvement = last_avg - first_avg
    
    print(f"  åˆæœŸå¹³å‡Return (Ep 0-50): {first_avg:.2f}")
    print(f"  åæœŸå¹³å‡Return (æœ€å50): {last_avg:.2f}")
    print(f"  æ”¹è¿›å¹…åº¦: {improvement:+.2f} ({improvement/abs(first_avg)*100:+.1f}%)")
    
    if improvement > 0:
        print(f"  âœ… è®­ç»ƒæœ‰æ”¹è¿›!")
    else:
        print(f"  âš ï¸  è®­ç»ƒæœªè§æ˜æ˜¾æ”¹è¿›")

# ç¢°æ’åˆ†æï¼ˆåŸºäºEpisode Lengthï¼‰
print(f"\nğŸ’¥ **ç¢°æ’æ¨æ–­åˆ†æ**")
print(f"  æ³¨æ„ï¼šæ–°ç‰ˆæœ¬æ—¥å¿—ä¼šæ˜¾ç¤ºå…·ä½“ç¢°æ’ç±»å‹ï¼ˆè¡Œäºº/corridor/è¾¹ç•Œï¼‰")

# æçŸ­episode (â‰¤10æ­¥) å¾ˆå¯èƒ½æ˜¯ç«‹å³ç¢°æ’
immediate_collision = (episode_lengths <= 10).sum()
print(f"  ç–‘ä¼¼ç«‹å³ç¢°æ’ (â‰¤10æ­¥): {immediate_collision}/{total_episodes} ({immediate_collision/total_episodes:.1%})")

# ä¸­ç­‰é•¿åº¦ä½†å¤±è´¥çš„episode
medium_fail = ((episode_lengths > 10) & (episode_lengths < 100) & (episode_returns < 0)).sum()
print(f"  ä¸­é€”ç¢°æ’ (10-100æ­¥ä¸”å¤±è´¥): {medium_fail}/{total_episodes} ({medium_fail/total_episodes:.1%})")

# è¯„ä¼°ç»“è®º
print(f"\n" + "=" * 80)
print("ğŸ“ **æ€»ä½“è¯„ä¼°**".center(80))
print("=" * 80)

final_success_rate = (last_50_returns > 0).sum() / 50
final_avg_return = last_50_returns.mean()

if final_success_rate >= 0.5:
    print("  âœ… **è®­ç»ƒæ•ˆæœè‰¯å¥½**")
    print(f"     - æœ€å50é›†æˆåŠŸç‡: {final_success_rate:.1%}")
elif final_success_rate >= 0.2:
    print("  âš ï¸  **è®­ç»ƒæ•ˆæœä¸€èˆ¬**")
    print(f"     - æœ€å50é›†æˆåŠŸç‡: {final_success_rate:.1%}")
    print(f"     - å»ºè®®ï¼šç»§ç»­è®­ç»ƒæˆ–è°ƒæ•´å¥–åŠ±å‡½æ•°")
else:
    print("  âŒ **è®­ç»ƒæ•ˆæœä¸ä½³**")
    print(f"     - æœ€å50é›†æˆåŠŸç‡: {final_success_rate:.1%}")
    print(f"     - å»ºè®®ï¼šæ£€æŸ¥å¥–åŠ±å‡½æ•°ã€ç½‘ç»œç»“æ„æˆ–ç¯å¢ƒè®¾ç½®")

if immediate_collision / total_episodes > 0.3:
    print(f"\n  âš ï¸  **é«˜ç¢°æ’ç‡è­¦å‘Š**")
    print(f"     - {immediate_collision/total_episodes:.1%} çš„episodeåœ¨10æ­¥å†…ç»“æŸ")
    print(f"     - å»ºè®®æŸ¥çœ‹æ–°æ—¥å¿—ç¡®è®¤æ˜¯'è¡Œäººç¢°æ’'è¿˜æ˜¯'corridorç¢°æ’'")
    print(f"     - å¦‚æœä¸»è¦æ˜¯è¡Œäººç¢°æ’ï¼šå¢å¤§è¡Œäººç”Ÿæˆè·ç¦»")
    print(f"     - å¦‚æœä¸»è¦æ˜¯corridorç¢°æ’ï¼šæ£€æŸ¥èµ·ç‚¹æ˜¯å¦åœ¨corridorå†…")

print("\n" + "=" * 80)
print(f"ğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®ï¼šè¿è¡Œä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹è¯¦ç»†æ—¥å¿—ï¼Œç¡®è®¤ç¢°æ’ç±»å‹")
print(f"   python scripts/resume_train.py --checkpoint logs/resume_training_optimized_20251006_184735/checkpoint_final.pt --config configs/resume_training_tuned.yaml")
print("=" * 80)

