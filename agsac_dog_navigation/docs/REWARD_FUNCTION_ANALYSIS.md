# ğŸ¯ å¥–åŠ±å‡½æ•°è®¾è®¡åˆ†æ

**æ›´æ–°æ—¶é—´**: 2025-10-04 00:15  
**çŠ¶æ€**: âš ï¸ **éœ€è¦ä¼˜åŒ–**

---

## ğŸ“Š å½“å‰å¥–åŠ±å‡½æ•°

### **ç»„æˆéƒ¨åˆ†**

```python
total_reward = (
    progress_reward +       # ~10.0 per meter (ä¸»å¯¼)
    direction_reward +      # 0~0.3 (æ–¹å‘ä¸€è‡´æ€§)
    curvature_reward +      # -0.5~0.5 (è·¯å¾„å¹³æ»‘åº¦)
    goal_reached_reward +   # 100.0 (ç¨€ç–)
    collision_penalty +     # -50.0 (ç¨€ç–)
    step_penalty +          # -0.001 (æå°)
    distance_penalty        # ~-0.01 (æå°)
)
```

### **å…·ä½“å®ç°**

```python
# 1. è¿›å±•å¥–åŠ±ï¼ˆä¸»å¯¼ï¼‰
progress = last_distance - current_distance
progress_reward = progress * 10.0
# èŒƒå›´: -10.0 ~ +10.0 per step
# å‡è®¾æ¯æ­¥0.1ç±³ï¼Œåˆ™ Â±1.0

# 2. æ–¹å‘ä¸€è‡´æ€§GDE
direction_score = GDE(path, goal_direction)  # âˆˆ [0, 1]
direction_reward = direction_score * 0.3
# èŒƒå›´: 0 ~ 0.3

# 3. è·¯å¾„å¹³æ»‘åº¦GDE
curvature_score = evaluate_curvature(path)  # âˆˆ (0, 1]
normalized = 2.0 * curvature_score - 1.0    # âˆˆ [-1, 1]
curvature_reward = normalized * 0.5
# èŒƒå›´: -0.5 ~ 0.5

# 4. åˆ°è¾¾ç›®æ ‡
goal_reached_reward = 100.0 if distance < 0.5 else 0.0
# èŒƒå›´: 0 æˆ– 100.0

# 5. ç¢°æ’æƒ©ç½š
collision_penalty = -50.0 if collision else 0.0
# èŒƒå›´: 0 æˆ– -50.0

# 6. æ­¥æ•°æƒ©ç½š
step_penalty = -0.001
# å›ºå®š: -0.001

# 7. è·ç¦»æƒ©ç½š
distance_penalty = -current_distance * 0.001
# èŒƒå›´: -0.01 ~ 0 (å‡è®¾è·ç¦»10ç±³)
```

---

## âœ… åˆç†çš„æ–¹é¢

### **1. ä¸»å¯¼å¥–åŠ±æ˜ç¡®**
```
progress_reward (~Â±1.0) >> direction + curvature (0.8)
```
âœ… **ä¼˜åŠ¿**ï¼š
- è¿›å±•æ˜¯ä¸»è¦ä¼˜åŒ–ç›®æ ‡
- ç¬¦åˆä»»åŠ¡ç›®æ ‡ï¼ˆåˆ°è¾¾ç»ˆç‚¹ï¼‰
- æƒé‡åˆç†ï¼Œå ä¸»å¯¼åœ°ä½

### **2. GDEå¥–åŠ±ä½œä¸ºæ­£åˆ™åŒ–**
```
direction_reward: 0~0.3
curvature_reward: -0.5~0.5
æ€»è®¡: -0.5~0.8 (çº¦ä¸ºprogressçš„8-80%)
```
âœ… **ä¼˜åŠ¿**ï¼š
- ä¸ä¼šå®Œå…¨ä¸»å¯¼è®­ç»ƒ
- èµ·åˆ°è·¯å¾„è´¨é‡å¼•å¯¼ä½œç”¨
- æƒé‡é€‚ä¸­

### **3. ç¨€ç–å¥–åŠ±è®¾ç½®åˆç†**
```
goal_reached: +100.0 (ç›¸å½“äº10ç±³è¿›å±•)
collision: -50.0 (ç›¸å½“äº5ç±³å€’é€€)
```
âœ… **ä¼˜åŠ¿**ï¼š
- ç›®æ ‡å¥–åŠ±è¶³å¤Ÿå¤§ï¼Œæ˜ç¡®ç»ˆæç›®æ ‡
- ç¢°æ’æƒ©ç½šè¶³å¤Ÿå¤§ï¼Œå¼ºè°ƒå®‰å…¨é‡è¦æ€§
- æ¯”ä¾‹åˆç†ï¼ˆ2:1ï¼‰

### **4. æå°æƒ©ç½šä¸ä¼šå¹²æ‰°**
```
step_penalty: -0.001
distance_penalty: ~-0.01
æ€»è®¡: ~-0.011 (ä»…å progressçš„1%)
```
âœ… **ä¼˜åŠ¿**ï¼š
- é¼“åŠ±å¿«é€Ÿå®Œæˆï¼Œä½†ä¸ä¼šå‹è¿‡ä¸»è¦ä¿¡å·
- é¿å…åœæ»ï¼Œä½†å½±å“æå°

---

## âš ï¸ å­˜åœ¨çš„é—®é¢˜

### **é—®é¢˜1: æ–¹å‘å’Œæ›²ç‡å¥–åŠ±ä¸å¹³è¡¡**

```python
direction_reward: 0 ~ 0.3      # åªèƒ½ä¸ºæ­£
curvature_reward: -0.5 ~ 0.5   # å¯æ­£å¯è´Ÿ
```

**é—®é¢˜**ï¼š
- æ–¹å‘å¥–åŠ±æ€»æ˜¯â‰¥0ï¼Œå³ä½¿æ–¹å‘å®Œå…¨é”™è¯¯ä¹Ÿä¸ä¼šæƒ©ç½š
- æ›²ç‡å¥–åŠ±å¯ä»¥ä¸ºè´Ÿï¼Œå¯¹å¼¯æ›²è·¯å¾„æƒ©ç½šè¾ƒé‡

**å½±å“**ï¼š
- å¯èƒ½å¯¼è‡´æœºå™¨äººå³ä½¿æ–¹å‘é”™è¯¯ï¼Œä¹Ÿå› ä¸ºæ›²ç‡å¥½è€Œè·å¾—å‡€æ­£å¥–åŠ±
- ä¸å¯¹ç§°çš„å¥–åŠ±å¯èƒ½å½±å“ç­–ç•¥å­¦ä¹ 

**å»ºè®®ä¿®å¤**ï¼š
```python
# æ–¹æ¡ˆ1: å°†directionä¹Ÿè®¾ä¸ºå¯è´Ÿ
direction_score_normalized = 2.0 * direction_score - 1.0  # âˆˆ [-1, 1]
direction_reward = direction_score_normalized * 0.3       # âˆˆ [-0.3, 0.3]

# æ–¹æ¡ˆ2: é™ä½curvatureæƒé‡
curvature_reward = normalized_curvature * 0.2  # âˆˆ [-0.2, 0.2]
```

### **é—®é¢˜2: distance_penaltyå¯èƒ½å¯¼è‡´å±€éƒ¨åœæ»**

```python
distance_penalty = -current_distance * 0.001
```

**é—®é¢˜**ï¼š
- è·ç¦»è¶Šè¿œï¼Œæƒ©ç½šè¶Šå¤§
- ä½†å¦‚æœåœ¨ç»•éšœç¢ç‰©ï¼Œè·ç¦»å¯èƒ½æš‚æ—¶å¢åŠ 
- å¯èƒ½æƒ©ç½šå¿…è¦çš„ç»•è¡Œè¡Œä¸º

**å½±å“**ï¼š
- é¼“åŠ±ç›´çº¿æ¥è¿‘ï¼Œä¸åˆ©äºç»•éšœ
- ä¸progress_rewardæœ‰é‡å¤

**å»ºè®®ä¿®å¤**ï¼š
```python
# æ–¹æ¡ˆ1: å®Œå…¨åˆ é™¤distance_penaltyï¼ˆprogresså·²ç»åŒ…å«äº†ï¼‰
# distance_penalty = 0

# æ–¹æ¡ˆ2: åªåœ¨è·ç¦»ä¸å˜æ—¶æƒ©ç½šï¼ˆé¿å…åœæ»ï¼‰
if abs(progress) < 0.01:  # å‡ ä¹æ²¡æœ‰è¿›å±•
    stagnation_penalty = -0.01
else:
    stagnation_penalty = 0
```

### **é—®é¢˜3: step_penaltyå¯èƒ½è¿‡å°**

```python
step_penalty = -0.001  # æ¯æ­¥
max_steps = 200        # æœ€å¤§æ­¥æ•°
total = -0.2           # æœ€å¤š200æ­¥çš„æƒ©ç½š
```

**é—®é¢˜**ï¼š
- 200æ­¥çš„æƒ©ç½šåªæœ‰-0.2
- è¿œå°äº1ç±³çš„è¿›å±•å¥–åŠ±(10.0)
- å‡ ä¹æ²¡æœ‰é¼“åŠ±æ•ˆç‡çš„ä½œç”¨

**å½±å“**ï¼š
- æœºå™¨äººå¯èƒ½å­¦ä¼šç¼“æ…¢ç§»åŠ¨ï¼ˆå°å¿ƒç¿¼ç¿¼ï¼‰
- ä¸åˆ©äºå­¦ä¹ å¿«é€Ÿå®Œæˆä»»åŠ¡

**å»ºè®®ä¿®å¤**ï¼š
```python
# æ–¹æ¡ˆ1: å¢åŠ step_penalty
step_penalty = -0.01  # 200æ­¥ = -2.0ï¼Œç›¸å½“äº0.2ç±³å€’é€€

# æ–¹æ¡ˆ2: ä½¿ç”¨æˆåŠŸç‡å¥–åŠ±æ›¿ä»£
# åœ¨episodeç»“æŸæ—¶:
if done and goal_reached:
    efficiency_bonus = 100.0 * (1.0 - steps/max_steps)
```

### **é—®é¢˜4: GDEæƒé‡å¯èƒ½éœ€è¦åŠ¨æ€è°ƒæ•´**

```python
direction_reward = direction_score * 0.3   # å›ºå®šæƒé‡
curvature_reward = normalized * 0.5        # å›ºå®šæƒé‡
```

**é—®é¢˜**ï¼š
- è®­ç»ƒåˆæœŸï¼šæœºå™¨äººè¿˜ä¸ä¼šåˆ°è¾¾ç›®æ ‡
  - åº”è¯¥å…ˆå­¦ä¼š"å‘ç›®æ ‡ç§»åŠ¨"
  - GDEå¯èƒ½å¼•å…¥è¿‡å¤šå™ªå£°
  
- è®­ç»ƒåæœŸï¼šæœºå™¨äººå·²ç»ä¼šåˆ°è¾¾ç›®æ ‡
  - åº”è¯¥ä¼˜åŒ–è·¯å¾„è´¨é‡
  - GDEæƒé‡åº”è¯¥å¢åŠ 

**å»ºè®®ä¿®å¤**ï¼š
```python
# è¯¾ç¨‹å­¦ä¹ ç­–ç•¥
gde_weight = min(1.0, episode / 100)  # å‰100ä¸ªepisodeé€æ¸å¢åŠ 

direction_reward = direction_score * (0.3 * gde_weight)
curvature_reward = normalized * (0.5 * gde_weight)
```

### **é—®é¢˜5: ç¢°æ’åçš„æ¢å¤æœºåˆ¶ç¼ºå¤±**

```python
collision_penalty = -50.0 if collision else 0.0
# ç¢°æ’åï¼Œepisodeæ˜¯å¦ç»“æŸï¼Ÿ
```

**é—®é¢˜**ï¼š
- å¦‚æœç¢°æ’åç»§ç»­ï¼Œæœºå™¨äººå¯èƒ½å­¦ä¸åˆ°é¿éšœçš„é‡è¦æ€§
- å¦‚æœç¢°æ’åç«‹å³ç»“æŸï¼Œå¯èƒ½è¿‡äºä¸¥æ ¼ï¼Œå½±å“æ¢ç´¢

**å½“å‰å®ç°**ï¼šéœ€è¦æ£€æŸ¥

**å»ºè®®**ï¼š
```python
# æ–¹æ¡ˆ1: ç¢°æ’åç«‹å³ç»“æŸ (ä¸¥æ ¼)
if collision:
    done = True
    
# æ–¹æ¡ˆ2: å…è®¸å°ç¢°æ’ï¼Œå¤§ç¢°æ’ç»“æŸ (å®½æ¾)
if collision:
    collision_count += 1
    if collision_count >= 3:  # ç´¯è®¡3æ¬¡ç¢°æ’
        done = True
        
# æ–¹æ¡ˆ3: ç¢°æ’åç»™ä¸€å®šæ¢å¤æ—¶é—´
if collision:
    penalty = -50.0 - (50.0 * collision_count)  # é€’å¢æƒ©ç½š
```

---

## ğŸ“ˆ æ•°å€¼èŒƒå›´å¯¹æ¯”

### **å…¸å‹Episodeçš„å¥–åŠ±åˆ†å¸ƒ** (å‡è®¾10ç±³è·ç¦»ï¼Œ100æ­¥å®Œæˆ)

```
è¿›å±•å¥–åŠ±:
  10ç±³ Ã— 10.0 = +100.0  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (ä¸»å¯¼)

GDEå¥–åŠ±:
  æ–¹å‘ 0.3 Ã— 100æ­¥ = +30.0   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  æ›²ç‡ 0.2 Ã— 100æ­¥ = +20.0   â–ˆâ–ˆâ–ˆâ–ˆ
  æ€»è®¡: +50.0

åˆ°è¾¾å¥–åŠ±:
  +100.0  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

æ­¥æ•°æƒ©ç½š:
  -0.001 Ã— 100 = -0.1  â–ˆ (å‡ ä¹å¯å¿½ç•¥)

è·ç¦»æƒ©ç½š:
  å¹³å‡-5ç±³ Ã— 0.001 = -0.005 Ã— 100 = -0.5  â–ˆ

æ€»å¥–åŠ±:
  100 + 50 + 100 - 0.1 - 0.5 = +249.4
```

### **å¤±è´¥Episodeçš„å¥–åŠ±** (ç¢°æ’ï¼Œ50æ­¥)

```
è¿›å±•å¥–åŠ±:
  3ç±³ Ã— 10.0 = +30.0  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

GDEå¥–åŠ±:
  +25.0  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

ç¢°æ’æƒ©ç½š:
  -50.0  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (è´Ÿ)

æ­¥æ•°+è·ç¦»æƒ©ç½š:
  -0.1 - 0.3 = -0.4  â–ˆ (è´Ÿ)

æ€»å¥–åŠ±:
  30 + 25 - 50 - 0.4 = +4.6  (ä»ä¸ºæ­£!)
```

**âš ï¸ å‘ç°é‡å¤§é—®é¢˜**ï¼šå³ä½¿ç¢°æ’ï¼Œæ€»å¥–åŠ±ä»å¯èƒ½ä¸ºæ­£ï¼

---

## ğŸ¯ æ”¹è¿›å»ºè®®

### **ä¼˜å…ˆçº§1: ä¿®å¤å¯¹ç§°æ€§** (é‡è¦)

```python
# ä¿®æ”¹direction_rewardä¸ºå¯è´Ÿ
direction_score_normalized = 2.0 * direction_score - 1.0
direction_reward = direction_score_normalized * 0.3  # âˆˆ [-0.3, 0.3]

# æˆ–è€…å¢åŠ ç¢°æ’æƒ©ç½š
collision_penalty = -100.0 if collision else 0.0  # ä»-50å¢åŠ åˆ°-100
```

### **ä¼˜å…ˆçº§2: åˆ é™¤distance_penalty** (å»ºè®®)

```python
# progress_rewardå·²ç»åŒ…å«äº†è·ç¦»ä¿¡æ¯
# distance_penaltyæ˜¯å†—ä½™çš„ï¼Œä¸”å¯èƒ½æƒ©ç½šç»•éšœè¡Œä¸º
distance_penalty = 0  # åˆ é™¤
```

### **ä¼˜å…ˆçº§3: å¢åŠ step_penalty** (å»ºè®®)

```python
# ä»-0.001å¢åŠ åˆ°-0.01
step_penalty = -0.01  # 200æ­¥ = -2.0
```

### **ä¼˜å…ˆçº§4: GDEæƒé‡è¯¾ç¨‹å­¦ä¹ ** (å¯é€‰)

```python
# è®­ç»ƒåˆæœŸé™ä½GDEå½±å“
gde_weight = min(1.0, self.episode_count / 100)

direction_reward = direction_score * (0.3 * gde_weight)
curvature_reward = normalized_curvature * (0.5 * gde_weight)
```

### **ä¼˜å…ˆçº§5: ç¢°æ’å³ç»ˆæ­¢** (å¼ºçƒˆå»ºè®®)

```python
# ç¡®ä¿ç¢°æ’åç«‹å³ç»“æŸepisode
if collision:
    done = True
    # ä¸”ç¢°æ’æƒ©ç½šåº”è¶³å¤Ÿå¤§
    collision_penalty = -100.0
```

---

## ğŸ“Š æ”¹è¿›åçš„å¥–åŠ±å‡½æ•°

### **å»ºè®®ç‰ˆæœ¬1: ä¿å®ˆæ”¹è¿›**

```python
def _compute_base_reward(self, action, collision):
    # 1. è¿›å±•å¥–åŠ±ï¼ˆä¸å˜ï¼‰
    progress = self.last_distance - current_distance
    progress_reward = progress * 10.0
    
    # 2. æ–¹å‘GDEï¼ˆæ”¹ä¸ºå¯¹ç§°ï¼‰
    direction_score = self.gde(path, reference).item()
    direction_normalized = 2.0 * direction_score - 1.0  # [-1, 1]
    direction_reward = direction_normalized * 0.3        # [-0.3, 0.3]
    
    # 3. æ›²ç‡GDEï¼ˆä¸å˜ï¼‰
    curvature_score = self._evaluate_path_curvature(path)
    curvature_normalized = 2.0 * curvature_score - 1.0
    curvature_reward = curvature_normalized * 0.5
    
    # 4. åˆ°è¾¾å¥–åŠ±ï¼ˆä¸å˜ï¼‰
    goal_reached_reward = 100.0 if distance < 0.5 else 0.0
    
    # 5. ç¢°æ’æƒ©ç½šï¼ˆå¢å¤§ï¼‰
    collision_penalty = -100.0 if collision else 0.0
    
    # 6. æ­¥æ•°æƒ©ç½šï¼ˆå¢åŠ ï¼‰
    step_penalty = -0.01
    
    # 7. åˆ é™¤distance_penalty
    
    total_reward = (
        progress_reward +
        direction_reward +
        curvature_reward +
        goal_reached_reward +
        collision_penalty +
        step_penalty
    )
    
    return total_reward
```

### **å»ºè®®ç‰ˆæœ¬2: æ¿€è¿›æ”¹è¿›**

```python
def _compute_base_reward(self, action, collision):
    # 1. è¿›å±•å¥–åŠ±ï¼ˆå¢åŠ æƒé‡ï¼‰
    progress_reward = progress * 15.0  # ä»10.0å¢åŠ åˆ°15.0
    
    # 2-3. GDEå¥–åŠ±ï¼ˆè¯¾ç¨‹å­¦ä¹ ï¼‰
    gde_weight = min(1.0, self.episode_count / 100)
    direction_reward = direction_normalized * (0.3 * gde_weight)
    curvature_reward = curvature_normalized * (0.5 * gde_weight)
    
    # 4. åˆ°è¾¾å¥–åŠ±ï¼ˆå¢åŠ ï¼‰
    goal_reached_reward = 150.0 if distance < 0.5 else 0.0
    
    # 5. ç¢°æ’æƒ©ç½šï¼ˆå¤§å¹…å¢åŠ ï¼‰
    collision_penalty = -150.0 if collision else 0.0
    
    # 6. æ•ˆç‡å¥–åŠ±ï¼ˆæ–°å¢ï¼‰
    if goal_reached and not collision:
        efficiency_bonus = 50.0 * (1.0 - steps / max_steps)
    else:
        efficiency_bonus = 0.0
    
    # 7. æ­¥æ•°æƒ©ç½š
    step_penalty = -0.02
    
    total_reward = (
        progress_reward +
        direction_reward +
        curvature_reward +
        goal_reached_reward +
        collision_penalty +
        efficiency_bonus +
        step_penalty
    )
    
    return total_reward
```

---

## ğŸ” æ€»ç»“

### **å½“å‰å¥–åŠ±å‡½æ•°è¯„åˆ†**

| æ–¹é¢ | è¯„åˆ† | è¯´æ˜ |
|------|------|------|
| **ä¸»å¯¼å¥–åŠ±** | âœ… 9/10 | progress_rewardè®¾è®¡è‰¯å¥½ |
| **GDEå¹³è¡¡** | âš ï¸ 6/10 | æ–¹å‘å¥–åŠ±ä¸å¯¹ç§°ï¼Œéœ€ä¿®å¤ |
| **ç¨€ç–å¥–åŠ±** | âš ï¸ 7/10 | ç¢°æ’æƒ©ç½šå¯èƒ½ä¸å¤Ÿ |
| **æ•ˆç‡æ¿€åŠ±** | âŒ 3/10 | step_penaltyè¿‡å° |
| **å¥–åŠ±å†—ä½™** | âš ï¸ 6/10 | distance_penaltyå†—ä½™ |
| **æ€»ä½“** | âš ï¸ **6.2/10** | **éœ€è¦ä¼˜åŒ–** |

### **æ ¸å¿ƒé—®é¢˜**
1. âŒ **æ–¹å‘å¥–åŠ±ä¸å¯¹ç§°** - éœ€è¦ä¿®å¤
2. âŒ **ç¢°æ’æƒ©ç½šå¯èƒ½ä¸å¤Ÿ** - ç¢°æ’åä»å¯èƒ½è·å¾—æ­£å¥–åŠ±
3. âš ï¸ **ç¼ºä¹æ•ˆç‡æ¿€åŠ±** - step_penaltyè¿‡å°
4. âš ï¸ **distance_penaltyå†—ä½™** - ä¸progressé‡å¤

### **å»ºè®®ä¼˜å…ˆçº§**
1. **ç«‹å³ä¿®å¤**: æ–¹å‘å¥–åŠ±å¯¹ç§°æ€§ + å¢åŠ ç¢°æ’æƒ©ç½š
2. **å»ºè®®ä¿®æ”¹**: åˆ é™¤distance_penalty + å¢åŠ step_penalty
3. **å¯é€‰ä¼˜åŒ–**: GDEè¯¾ç¨‹å­¦ä¹  + æ•ˆç‡å¥–åŠ±

---

**ç»“è®º**: å½“å‰å¥–åŠ±å‡½æ•°åŸºç¡€è‰¯å¥½ï¼Œä½†å­˜åœ¨ä¸€äº›éœ€è¦ä¿®å¤çš„é—®é¢˜ã€‚å»ºè®®è‡³å°‘å®æ–½"ä¼˜å…ˆçº§1-2"çš„æ”¹è¿›ã€‚ğŸ¯

