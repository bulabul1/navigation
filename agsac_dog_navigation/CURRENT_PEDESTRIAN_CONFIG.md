# 当前行人和轨迹预测配置

**更新时间**: 2025-10-05  
**配置文件**: `configs/resume_training_tuned.yaml`

---

## 📊 配置总览

### **1. 轨迹预测数量**

```yaml
model:
  num_modes: 3  # 每个行人预测3条轨迹
```

**说明：**
- 预训练模型（SocialCircle+E-V2-Net）本身支持20条轨迹
- 为降低参数量和训练复杂度，我们只取前3条
- 3条轨迹足以覆盖行人的主要移动模式

---

### **2. 最大行人数量**

```yaml
env:
  max_pedestrians: 10  # 模型架构支持的最大行人数

model:
  max_pedestrians: 10  # 编码器维度
```

**说明：**
- 这是模型架构的上限（PedestrianEncoder的容量）
- 实际场景中的行人数量可能少于10个
- 使用mask机制处理实际数量不足的情况

---

### **3. 实际场景行人数量**

```python
# corridor_generator.py
if difficulty == 'easy':
    num_pedestrians = randint(2, 4)  # 2-3个行人

elif difficulty == 'medium':
    num_pedestrians = randint(2, 4)  # 2-3个行人

else:  # hard
    num_pedestrians = randint(2, 4)  # 2-3个行人
```

**当前配置（已优化）：**
- ✅ 所有难度统一：**2-3个行人**
- ✅ 取消了障碍物
- ✅ 降低复杂度，聚焦基础导航学习

**原配置（已废弃）：**
- ❌ Easy: 1-2个
- ❌ Medium: 3-5个
- ❌ Hard: 5-9个（过于复杂）

---

## 🎯 数据流示例

### **场景：3个行人，每人预测3条轨迹**

```python
# 输入观测
pedestrian_observations: (3, 8, 2)
  # 3个行人，8帧历史，(x,y)坐标

pedestrian_mask: (3,)
  # [True, True, True] - 3个行人都有效

# 预测输出
predicted_trajectories: (3, 12, 2, 3)
  # 3个行人，12帧未来，(x,y)坐标，3条模态轨迹
  
# 维度解释
batch=1
num_pedestrians=3
pred_horizon=12
xy=2
num_modes=3
```

### **场景：2个行人（实际 < 最大容量）**

```python
# 输入观测
pedestrian_observations: (10, 8, 2)  # padding到max_pedestrians
  # 前2个行人：真实数据
  # 后8个：全零padding

pedestrian_mask: (10,)
  # [True, True, False, False, False, False, False, False, False, False]
  # 只有前2个有效

# 预测输出
predicted_trajectories: (10, 12, 2, 3)
  # 只有前2个行人的预测是有效的
  # 后8个会被mask屏蔽
```

---

## 📈 参数量对比

### **当前配置（优化后）**

```
每个行人预测: 3条轨迹 × 12帧 × 2维 = 72个值
最多3个行人: 72 × 3 = 216个预测值
```

**参数量：**
- PedestrianEncoder: ~225K参数
- TrajectoryPredictor: 0参数（冻结的预训练模型）

### **原始配置（如果用20条轨迹）**

```
每个行人预测: 20条轨迹 × 12帧 × 2维 = 480个值
最多9个行人: 480 × 9 = 4,320个预测值
```

**问题：**
- 预测值爆炸（4,320 vs 216）
- 训练极慢
- 信息冗余（20条轨迹太多）

---

## 🔍 为什么3条轨迹足够？

### **行人移动模式**

典型行人在12帧（1.2秒）内只有几种行为：
1. **直行** - 保持当前方向
2. **左转/右转** - 改变方向
3. **停止/减速** - 速度变化

3条轨迹可以覆盖：
- 轨迹1：继续直行（高概率）
- 轨迹2：向左转（中概率）
- 轨迹3：向右转或减速（低概率）

### **实际验证**

预训练模型输出的20条轨迹中：
- 前3-5条通常包含最主要的模式
- 后面的轨迹概率极低（< 1%）
- 对决策影响微小

---

## 💡 调整建议

### **如果碰撞率仍然很高（> 30%）：**

**选项1：减少行人数量**
```python
# corridor_generator.py
num_pedestrians = self.rng.randint(1, 3)  # 1-2个
```

**选项2：增加轨迹预测数量**
```yaml
model:
  num_modes: 5  # 增加到5条
```

**权衡：**
- 减少行人：更容易学习，但场景过于简单
- 增加轨迹：更精确预测，但训练稍慢

---

### **如果成功率很高（> 60%）：**

**选项：增加挑战**
```python
# corridor_generator.py
if difficulty == 'hard':
    num_pedestrians = self.rng.randint(3, 5)  # 增加到3-4个
```

---

## 📋 当前训练配置总结

```yaml
场景生成:
  行人数量: 2-3个（随机）
  障碍物: 0个
  通路: 2-4条（根据难度）

模型架构:
  最大支持行人: 10个
  实际使用: 2-3个
  每人预测轨迹: 3条
  预测时长: 12帧（1.2秒）

总预测量:
  最大: 3人 × 3轨迹 × 12帧 × 2维 = 216个值
  实际: 平均2.5人 → 180个值
```

---

## 🎯 总结

| 配置项 | 值 | 说明 |
|--------|-----|------|
| **实际行人数** | 2-3个 | 所有难度统一 ✅ |
| **预测轨迹数** | 3条/人 | 优化后（原20条） ✅ |
| **最大支持** | 10个 | 架构容量 |
| **预测时长** | 12帧 | 1.2秒 |
| **参数量** | ~225K | PedestrianEncoder |

**设计理念：**
- ✅ 降低复杂度，聚焦基础学习
- ✅ 3条轨迹覆盖主要模式
- ✅ 2-3个行人平衡难度与可学习性

---

**当前配置已优化，适合训练！** 🚀
