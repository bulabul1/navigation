# AGSAC å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸš€ å¿«é€Ÿä½¿ç”¨

### 1. åˆ›å»ºæ¨¡å‹

```python
from agsac.models import AGSACModel
import torch

# åˆå§‹åŒ–æ¨¡å‹
model = AGSACModel(
    # ç‰¹å¾ç»´åº¦
    dog_feature_dim=64,
    corridor_feature_dim=128,
    pedestrian_feature_dim=128,
    fusion_dim=64,
    action_dim=22,
    
    # åœºæ™¯é…ç½®
    max_pedestrians=10,
    max_corridors=5,
    max_vertices=20,
    obs_horizon=8,
    pred_horizon=12,
    num_modes=20,
    
    # ç½‘ç»œé…ç½®
    hidden_dim=128,
    num_heads=4,
    dropout=0.1,
    
    # SACé…ç½®
    actor_lr=1e-4,
    critic_lr=1e-4,
    alpha_lr=3e-4,
    gamma=0.99,
    tau=0.005,
    auto_entropy=True,
    max_grad_norm=1.0,
    
    # è®¾å¤‡
    device='cuda'  # æˆ– 'cpu'
)

print(f"æ¨¡å‹æ€»å‚æ•°: {sum(p.numel() for p in model.parameters()):,}")
```

### 2. å‡†å¤‡è§‚æµ‹æ•°æ®

```python
batch_size = 4

observation = {
    # æœºå™¨ç‹—çŠ¶æ€
    'dog': {
        'trajectory': torch.randn(batch_size, 8, 2),  # å†å²è½¨è¿¹
        'velocity': torch.randn(batch_size, 2),        # å½“å‰é€Ÿåº¦
        'position': torch.randn(batch_size, 2),        # å½“å‰ä½ç½®
        'goal': torch.randn(batch_size, 2)             # ç›®æ ‡ä½ç½®
    },
    
    # è¡Œäººè½¨è¿¹
    'pedestrians': {
        'trajectories': torch.randn(batch_size, 10, 8, 2),  # (batch, max_peds, obs_horizon, 2)
        'mask': torch.ones(batch_size, 10)                   # 1=æœ‰æ•ˆ, 0=padding
    },
    
    # èµ°å»Šå‡ ä½•
    'corridors': {
        'polygons': torch.randn(batch_size, 5, 20, 2),  # (batch, max_corridors, max_vertices, 2)
        'vertex_counts': torch.tensor([[10, 8, 6, 4, 3]] * batch_size),  # æ¯ä¸ªèµ°å»Šçš„å®é™…é¡¶ç‚¹æ•°
        'mask': torch.ones(batch_size, 5)               # 1=æœ‰æ•ˆ, 0=padding
    },
    
    # å‚è€ƒçº¿ï¼ˆç”¨äºGDEè¯„ä¼°ï¼‰
    'reference_line': torch.randn(batch_size, 2, 2)  # èµ·ç‚¹å’Œç»ˆç‚¹
}
```

### 3. æ¨ç†ï¼ˆæ•°æ®æ”¶é›†ï¼‰

```python
# åˆå§‹åŒ–éšè—çŠ¶æ€
hidden_states = model.init_hidden_states(batch_size=1)

# å•æ­¥æ¨ç†
action, log_prob, hidden_states = model.select_action(
    observation=observation,
    hidden_states=hidden_states,
    deterministic=False  # False=éšæœºé‡‡æ ·, True=ç¡®å®šæ€§
)

print(f"åŠ¨ä½œ: {action.shape}")        # (batch, 22)
print(f"å¯¹æ•°æ¦‚ç‡: {log_prob.shape}")  # (batch,)
```

### 4. å®Œæ•´å‰å‘ä¼ æ’­ï¼ˆå¸¦è°ƒè¯•ä¿¡æ¯ï¼‰

```python
result = model.forward(
    observation=observation,
    hidden_states=None,  # Noneä¼šè‡ªåŠ¨åˆå§‹åŒ–
    deterministic=False,
    return_attention=True  # è¿”å›æ³¨æ„åŠ›æƒé‡
)

# è¾“å‡ºåŒ…å«
print(f"åŠ¨ä½œ: {result['action'].shape}")              # (batch, 22)
print(f"Q1å€¼: {result['q1'].shape}")                  # (batch,)
print(f"Q2å€¼: {result['q2'].shape}")                  # (batch,)
print(f"èåˆç‰¹å¾: {result['fused_state'].shape}")     # (batch, 64)
print(f"éšè—çŠ¶æ€: {list(result['hidden_states'].keys())}")  # ['actor', 'critic1', 'critic2']

# è°ƒè¯•ä¿¡æ¯
debug = result['debug_info']
print(f"æœºå™¨ç‹—ç‰¹å¾: {debug['dog_features'].shape}")           # (batch, 64)
print(f"èµ°å»Šç‰¹å¾: {debug['corridor_features'].shape}")         # (batch, 128)
print(f"è¡Œäººé¢„æµ‹: {debug['pedestrian_predictions'].shape}")    # (batch, max_peds, 12, 2, 20)
print(f"è¡Œäººç‰¹å¾: {debug['pedestrian_features'].shape}")       # (batch, 64)
```

### 5. è®­ç»ƒï¼ˆä½¿ç”¨åºåˆ—æ®µï¼‰

```python
# å‡†å¤‡åºåˆ—æ®µbatch
segment_batch = [
    {
        'states': torch.randn(16, 64),     # åºåˆ—é•¿åº¦16
        'actions': torch.randn(16, 22),
        'rewards': torch.randn(16),
        'next_states': torch.randn(16, 64),
        'dones': torch.zeros(16),
        'init_hidden': {
            'actor': (torch.zeros(1, 1, 128), torch.zeros(1, 1, 128)),
            'critic1': (torch.zeros(1, 1, 128), torch.zeros(1, 1, 128)),
            'critic2': (torch.zeros(1, 1, 128), torch.zeros(1, 1, 128))
        }
    }
    # ... æ›´å¤šsegment
]

# è®­ç»ƒæ›´æ–°
model.train()
losses = model.update(segment_batch)

print(f"CriticæŸå¤±: {losses['critic_loss']:.4f}")
print(f"ActoræŸå¤±: {losses['actor_loss']:.4f}")
print(f"Alpha: {losses['alpha']:.4f}")

# è½¯æ›´æ–°ç›®æ ‡ç½‘ç»œ
model.soft_update_target()
```

### 6. ä¿å­˜å’ŒåŠ è½½æ¨¡å‹

```python
# ä¿å­˜æ£€æŸ¥ç‚¹
model.save_checkpoint('checkpoints/model_episode_1000.pth')

# åŠ è½½æ£€æŸ¥ç‚¹
model.load_checkpoint(
    'checkpoints/model_episode_1000.pth',
    load_optimizers=True  # æ˜¯å¦åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
)
```

---

## ğŸ“Š è§‚æµ‹æ•°æ®è¯¦ç»†è¯´æ˜

### æœºå™¨ç‹—çŠ¶æ€ (`observation['dog']`)
- **trajectory**: (batch, 8, 2) - è¿‡å»8ä¸ªæ—¶é—´æ­¥çš„ä½ç½®
- **velocity**: (batch, 2) - å½“å‰é€Ÿåº¦ [vx, vy]
- **position**: (batch, 2) - å½“å‰ä½ç½® [x, y]
- **goal**: (batch, 2) - ç›®æ ‡ä½ç½® [x, y]

### è¡Œäººè½¨è¿¹ (`observation['pedestrians']`)
- **trajectories**: (batch, max_peds, 8, 2) - æ¯ä¸ªè¡Œäººè¿‡å»8æ­¥çš„ä½ç½®
- **mask**: (batch, max_peds) - æœ‰æ•ˆæ€§æ©ç 
  - 1 = è¯¥è¡Œäººå­˜åœ¨
  - 0 = paddingï¼ˆä¸å­˜åœ¨çš„è¡Œäººï¼‰

### èµ°å»Šå‡ ä½• (`observation['corridors']`)
- **polygons**: (batch, max_corridors, max_vertices, 2)
  - æ¯ä¸ªèµ°å»Šæ˜¯ä¸€ä¸ªå¤šè¾¹å½¢
  - paddingçš„é¡¶ç‚¹è®¾ä¸º0
- **vertex_counts**: (batch, max_corridors) - æ¯ä¸ªèµ°å»Šçš„å®é™…é¡¶ç‚¹æ•°
- **mask**: (batch, max_corridors) - èµ°å»Šæœ‰æ•ˆæ€§æ©ç 

### å‚è€ƒçº¿ (`observation['reference_line']`)
- (batch, 2, 2) - èµ·ç‚¹ [x, y] å’Œ ç»ˆç‚¹ [x, y]
- ç”¨äºå‡ ä½•å¾®åˆ†è¯„ä¼°å™¨ï¼ˆGDEï¼‰è®¡ç®—è·¯å¾„è´¨é‡

---

## ğŸ¯ å…¸å‹è®­ç»ƒæµç¨‹

```python
from agsac.models import AGSACModel

# 1. åˆ›å»ºæ¨¡å‹
model = AGSACModel(...).to('cuda')

# 2. åˆå§‹åŒ–Replay Buffer
buffer = SequenceReplayBuffer(capacity=100000, seq_len=16)

# 3. è®­ç»ƒå¾ªç¯
for episode in range(num_episodes):
    # æ”¶é›†æ•°æ®
    observation = env.reset()
    hidden_states = model.init_hidden_states(batch_size=1)
    episode_data = []
    
    while not done:
        # é€‰æ‹©åŠ¨ä½œ
        action, log_prob, hidden_states = model.select_action(
            observation, hidden_states, deterministic=False
        )
        
        # æ‰§è¡ŒåŠ¨ä½œ
        next_obs, reward, done, info = env.step(action)
        
        # å­˜å‚¨transition
        episode_data.append({
            'observation': observation,
            'action': action,
            'reward': reward,
            'done': done,
            'hidden_states': hidden_states
        })
        
        observation = next_obs
    
    # å­˜å‚¨episode
    buffer.add_episode(episode_data)
    
    # è®­ç»ƒæ›´æ–°
    if buffer.size() >= warmup_steps:
        for _ in range(updates_per_episode):
            segment_batch = buffer.sample(batch_size)
            losses = model.update(segment_batch)
            model.soft_update_target()
    
    # å®šæœŸè¯„ä¼°å’Œä¿å­˜
    if episode % eval_interval == 0:
        evaluate(model, eval_env)
    
    if episode % save_interval == 0:
        model.save_checkpoint(f'checkpoint_{episode}.pth')
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. å‚æ•°é‡é—®é¢˜
å½“å‰æ¨¡å‹çº¦3Må‚æ•°ï¼Œè¶…å‡º2Mé¢„ç®—ã€‚ä¸»è¦åŸå› ï¼š
- TrajectoryPredictorå 67.6% (2.05Må‚æ•°)
- å»ºè®®ä½¿ç”¨é¢„è®­ç»ƒE-V2-Netæˆ–å‡å°‘é¢„æµ‹æ¨¡æ€æ•°

### 2. åæ ‡ç³»ç»Ÿ
- æ‰€æœ‰åæ ‡åº”åœ¨åŒä¸€å‚è€ƒç³»ä¸‹
- å»ºè®®ä½¿ç”¨æœºå™¨ç‹—å½“å‰ä½ç½®ä¸ºåŸç‚¹çš„å±€éƒ¨åæ ‡ç³»

### 3. æ•°æ®å½’ä¸€åŒ–
- é€Ÿåº¦ã€ä½ç½®ç­‰å»ºè®®å½’ä¸€åŒ–åˆ°åˆç†èŒƒå›´
- æœ‰åŠ©äºè®­ç»ƒç¨³å®šæ€§

### 4. Hidden Stateç®¡ç†
- æ¯ä¸ªepisodeå¼€å§‹æ—¶éœ€è¦é‡ç½®hidden states
- åºåˆ—æ®µé‡‡æ ·æ—¶éœ€è¦ä¿å­˜segmentèµ·å§‹çš„hidden state

### 5. è®¾å¤‡ä¸€è‡´æ€§
- ç¡®ä¿observationå’Œmodelåœ¨åŒä¸€è®¾å¤‡ä¸Šï¼ˆCPUæˆ–CUDAï¼‰
- å¯ä»¥ç”¨`.to(device)`ç§»åŠ¨æ•°æ®

---

## ğŸ”§ ä¸‹ä¸€æ­¥

1. **å®ç°ReplayBuffer** - åºåˆ—æ®µå­˜å‚¨å’Œé‡‡æ ·
2. **å®ç°Environment** - ç¯å¢ƒæ¥å£å°è£…
3. **å®ç°Trainer** - å®Œæ•´è®­ç»ƒæµç¨‹
4. **ä¼˜åŒ–å‚æ•°é‡** - å‡å°‘TrajectoryPredictorå‚æ•°

è¯¦è§ [INTEGRATION_STATUS.md](./INTEGRATION_STATUS.md)

